{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IN3062 Introduction to AI Project\n",
    "### Spotify Machine Learning Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a fan of music and an avid user of Spotify, I decided to use a dataset of over 160,000 songs each with granular information behind their charataristics such as: acousticness, energy, danceability and tempo. \n",
    "\n",
    "Each song also has a popularity score between 0 and 100 indicating how popular the song is with worldwide Spotify users, this interested me as I have the hypothesis: Is it possible to predict how popular a song could be based purely on characteristics?\n",
    "\n",
    "Let's explore this hypothesis..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Dataset\n",
    "\n",
    "The dataset can be located at https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks. \n",
    "\n",
    "I am using the main data.csv file to start, I will explore the additional datasets: data_by_genre.csv and data_by_artists later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring The Dataset\n",
    "\n",
    "Taking a look at the columns of the dataset we can see that each song has:\n",
    "\n",
    "'valence' = The positiveness of the song.\n",
    "\n",
    "'year' = The release year of the song.\n",
    "\n",
    "'acousticness' = The relative metric of the song being acoustic (not having electrical amplification).\n",
    "\n",
    "'artists' = An array containing the artist(s) name's.\n",
    "\n",
    "'danceability' = The relative measurement of the song being danceable.\n",
    "\n",
    "'duration_ms' = The duration of the song in miliseconds.\n",
    "\n",
    "'energy' = The relative measurement of the song's energy.\n",
    "\n",
    "'explicit' = A Boolean value indicating if the song contains explicit lyrics.\n",
    "\n",
    "'id' = The inique identifer for the song.\n",
    "\n",
    "'instrumentalness' = The relative ratio of the song being instrumental.\n",
    "\n",
    "'key' = The musical key that the song is recorded in. Represented as Integers between 0 and 11.\n",
    "\n",
    "'liveness' = The relative duration of the song sounding like a live performance.\n",
    "\n",
    "'loudness' = The relative loudness of the song in the range of [-60, 0] decibels (dB).\n",
    "\n",
    "'mode' = A Boolean value indicating if the song starts with a major chord progression or not.\n",
    "\n",
    "'name' = The name of the song.\n",
    "\n",
    "'popularity' = The current popularity of the song measured by Spotify. Represented as Integers between 0 and 100.\n",
    "\n",
    "'release_date' = The date of release of the song in yyyy-mm-dd, yyyy-mm or yyyy format.\n",
    "\n",
    "'speechiness' = The relative length of the song containing any kind of vocals.\n",
    "\n",
    "'tempo' = The musical tempo (speed) of the song.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0594</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.982</td>\n",
       "      <td>['Sergei Rachmaninoff', 'James Levine', 'Berli...</td>\n",
       "      <td>0.279</td>\n",
       "      <td>831667</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0</td>\n",
       "      <td>4BJqT0PrAfrxzMOxytFOIz</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-20.096</td>\n",
       "      <td>1</td>\n",
       "      <td>Piano Concerto No. 3 in D Minor, Op. 30: III. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>80.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9630</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.732</td>\n",
       "      <td>['Dennis Day']</td>\n",
       "      <td>0.819</td>\n",
       "      <td>180533</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0</td>\n",
       "      <td>7xPhfUan2yNtyFG0cUWkt8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-12.441</td>\n",
       "      <td>1</td>\n",
       "      <td>Clancy Lowered the Boom</td>\n",
       "      <td>5</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>60.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.961</td>\n",
       "      <td>['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>500062</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0</td>\n",
       "      <td>1o6I8BglA6ylDMrIELygv1</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-14.850</td>\n",
       "      <td>1</td>\n",
       "      <td>Gati Bali</td>\n",
       "      <td>5</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>110.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1650</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.967</td>\n",
       "      <td>['Frank Parker']</td>\n",
       "      <td>0.275</td>\n",
       "      <td>210000</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0</td>\n",
       "      <td>3ftBPsC5vPBKxYSee08FDH</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>5</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-9.316</td>\n",
       "      <td>1</td>\n",
       "      <td>Danny Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>100.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2530</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.957</td>\n",
       "      <td>['Phil Regan']</td>\n",
       "      <td>0.418</td>\n",
       "      <td>166693</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0</td>\n",
       "      <td>4d6HGyGT8e121BsdKmw9v6</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-10.096</td>\n",
       "      <td>1</td>\n",
       "      <td>When Irish Eyes Are Smiling</td>\n",
       "      <td>2</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>101.665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence  year  acousticness  \\\n",
       "0   0.0594  1921         0.982   \n",
       "1   0.9630  1921         0.732   \n",
       "2   0.0394  1921         0.961   \n",
       "3   0.1650  1921         0.967   \n",
       "4   0.2530  1921         0.957   \n",
       "\n",
       "                                             artists  danceability  \\\n",
       "0  ['Sergei Rachmaninoff', 'James Levine', 'Berli...         0.279   \n",
       "1                                     ['Dennis Day']         0.819   \n",
       "2  ['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...         0.328   \n",
       "3                                   ['Frank Parker']         0.275   \n",
       "4                                     ['Phil Regan']         0.418   \n",
       "\n",
       "   duration_ms  energy  explicit                      id  instrumentalness  \\\n",
       "0       831667   0.211         0  4BJqT0PrAfrxzMOxytFOIz          0.878000   \n",
       "1       180533   0.341         0  7xPhfUan2yNtyFG0cUWkt8          0.000000   \n",
       "2       500062   0.166         0  1o6I8BglA6ylDMrIELygv1          0.913000   \n",
       "3       210000   0.309         0  3ftBPsC5vPBKxYSee08FDH          0.000028   \n",
       "4       166693   0.193         0  4d6HGyGT8e121BsdKmw9v6          0.000002   \n",
       "\n",
       "   key  liveness  loudness  mode  \\\n",
       "0   10     0.665   -20.096     1   \n",
       "1    7     0.160   -12.441     1   \n",
       "2    3     0.101   -14.850     1   \n",
       "3    5     0.381    -9.316     1   \n",
       "4    3     0.229   -10.096     1   \n",
       "\n",
       "                                                name  popularity release_date  \\\n",
       "0  Piano Concerto No. 3 in D Minor, Op. 30: III. ...           4         1921   \n",
       "1                            Clancy Lowered the Boom           5         1921   \n",
       "2                                          Gati Bali           5         1921   \n",
       "3                                          Danny Boy           3         1921   \n",
       "4                        When Irish Eyes Are Smiling           2         1921   \n",
       "\n",
       "   speechiness    tempo  \n",
       "0       0.0366   80.954  \n",
       "1       0.4150   60.936  \n",
       "2       0.0339  110.339  \n",
       "3       0.0354  100.109  \n",
       "4       0.0380  101.665  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the top five songs are according to popularity, to judge if there is a trend in their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19611</th>\n",
       "      <td>0.145</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>['Bad Bunny', 'Jhay Cortez']</td>\n",
       "      <td>0.731</td>\n",
       "      <td>205090</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "      <td>47EiUVwUp4C9fGccaPuUCS</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-10.059</td>\n",
       "      <td>0</td>\n",
       "      <td>Dakiti</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>109.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19606</th>\n",
       "      <td>0.756</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>['24kGoldn', 'iann dior']</td>\n",
       "      <td>0.700</td>\n",
       "      <td>140526</td>\n",
       "      <td>0.722</td>\n",
       "      <td>1</td>\n",
       "      <td>3tjFYV6RSFtuktYl3ZtYcq</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>-3.558</td>\n",
       "      <td>0</td>\n",
       "      <td>Mood (feat. iann dior)</td>\n",
       "      <td>99</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>90.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>0.737</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>['BTS']</td>\n",
       "      <td>0.746</td>\n",
       "      <td>199054</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0</td>\n",
       "      <td>0t1kP63rueHleOhQkYSXFY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>-4.410</td>\n",
       "      <td>0</td>\n",
       "      <td>Dynamite</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>114.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19608</th>\n",
       "      <td>0.357</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>['Cardi B', 'Megan Thee Stallion']</td>\n",
       "      <td>0.935</td>\n",
       "      <td>187541</td>\n",
       "      <td>0.454</td>\n",
       "      <td>1</td>\n",
       "      <td>4Oun2ylbjFKMPTiaSbbCih</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>-7.509</td>\n",
       "      <td>1</td>\n",
       "      <td>WAP (feat. Megan Thee Stallion)</td>\n",
       "      <td>96</td>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>133.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19610</th>\n",
       "      <td>0.682</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>['Ariana Grande']</td>\n",
       "      <td>0.737</td>\n",
       "      <td>172325</td>\n",
       "      <td>0.802</td>\n",
       "      <td>1</td>\n",
       "      <td>35mvY5S1H3J2QZyna3TFe0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>-4.771</td>\n",
       "      <td>1</td>\n",
       "      <td>positions</td>\n",
       "      <td>96</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>144.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       valence  year  acousticness                             artists  \\\n",
       "19611    0.145  2020        0.4010        ['Bad Bunny', 'Jhay Cortez']   \n",
       "19606    0.756  2020        0.2210           ['24kGoldn', 'iann dior']   \n",
       "19618    0.737  2020        0.0112                             ['BTS']   \n",
       "19608    0.357  2020        0.0194  ['Cardi B', 'Megan Thee Stallion']   \n",
       "19610    0.682  2020        0.4680                   ['Ariana Grande']   \n",
       "\n",
       "       danceability  duration_ms  energy  explicit                      id  \\\n",
       "19611         0.731       205090   0.573         1  47EiUVwUp4C9fGccaPuUCS   \n",
       "19606         0.700       140526   0.722         1  3tjFYV6RSFtuktYl3ZtYcq   \n",
       "19618         0.746       199054   0.765         0  0t1kP63rueHleOhQkYSXFY   \n",
       "19608         0.935       187541   0.454         1  4Oun2ylbjFKMPTiaSbbCih   \n",
       "19610         0.737       172325   0.802         1  35mvY5S1H3J2QZyna3TFe0   \n",
       "\n",
       "       instrumentalness  key  liveness  loudness  mode  \\\n",
       "19611          0.000052    4    0.1130   -10.059     0   \n",
       "19606          0.000000    7    0.2720    -3.558     0   \n",
       "19618          0.000000    6    0.0936    -4.410     0   \n",
       "19608          0.000000    1    0.0824    -7.509     1   \n",
       "19610          0.000000    0    0.0931    -4.771     1   \n",
       "\n",
       "                                  name  popularity release_date  speechiness  \\\n",
       "19611                           Dakiti         100   2020-10-30       0.0544   \n",
       "19606           Mood (feat. iann dior)          99   2020-07-24       0.0369   \n",
       "19618                         Dynamite          97   2020-08-28       0.0993   \n",
       "19608  WAP (feat. Megan Thee Stallion)          96   2020-08-07       0.3750   \n",
       "19610                        positions          96   2020-10-30       0.0878   \n",
       "\n",
       "         tempo  \n",
       "19611  109.928  \n",
       "19606   90.989  \n",
       "19618  114.044  \n",
       "19608  133.073  \n",
       "19610  144.015  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nlargest(5, 'popularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from not enjoying any of these songs myself, we can draw that the main similarities that they exhibit are that they all have no or very low instrumentalness, a danceability > 7.0 and they were all released in 2020.\n",
    "\n",
    "So as a generalisation, we can say that 'dancy' songs released in 2020 with no instrumentals are likley to be popular. Lets see if the training can pick up on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing The Dataset\n",
    "\n",
    "If we take a look at the info behind the data frame, we can see that there are no null values for each column which is great as we won't need to remove any null values which would have resulted in losing some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 170653 entries, 0 to 170652\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   valence           170653 non-null  float64\n",
      " 1   year              170653 non-null  int64  \n",
      " 2   acousticness      170653 non-null  float64\n",
      " 3   artists           170653 non-null  object \n",
      " 4   danceability      170653 non-null  float64\n",
      " 5   duration_ms       170653 non-null  int64  \n",
      " 6   energy            170653 non-null  float64\n",
      " 7   explicit          170653 non-null  int64  \n",
      " 8   id                170653 non-null  object \n",
      " 9   instrumentalness  170653 non-null  float64\n",
      " 10  key               170653 non-null  int64  \n",
      " 11  liveness          170653 non-null  float64\n",
      " 12  loudness          170653 non-null  float64\n",
      " 13  mode              170653 non-null  int64  \n",
      " 14  name              170653 non-null  object \n",
      " 15  popularity        170653 non-null  int64  \n",
      " 16  release_date      170653 non-null  object \n",
      " 17  speechiness       170653 non-null  float64\n",
      " 18  tempo             170653 non-null  float64\n",
      "dtypes: float64(9), int64(6), object(4)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the data types for the majority of the columns are either Integer or Float values which are ready for training. However for 'artists', 'id', 'name' and 'release_date'. I will touch on 'artists' and 'name' later when I attempt to increase the accuracy of the predictions but for now we can drop it from the dataframe along with: 'id' and 'release_date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineDf = df.drop(columns=['id', 'artists', 'release_date', 'name', 'mode']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Training\n",
    "\n",
    "Now that the DataFrame has had the non-numeric objects removed we can start with the baseline training.\n",
    "To start I am going to create two dataframes, one for the dataIn (X) and one for the dataOut (y). \n",
    "\n",
    "Then using Scikit-learn's test_train_spilt I am going to split the training and testing data 80:20. \n",
    "\n",
    "And finally I will run the training data though a Linear Regression model, then test the predictions against the test data to get an accuracy score.\n",
    "\n",
    "The accuracy score is derived from the following measures:\n",
    "\n",
    "Mean Squared Error (MSE) - The mean average of which predicted data points stray away from the regresssion line. Lower is better.\n",
    "\n",
    "R Squared (R^2) - The statistical measure of how close the predicted data points are to the fitted regression line.\n",
    "The closer to 1 the better.\n",
    "\n",
    "With the R^2 score being multiplied by 100 and represented to five significant figures as the overall accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 113.74587287017013\n",
      "R^2: 0.7611216828203751\n",
      "Accuracy: 76.11217%\n",
      "\n",
      "=== Baseline Accuracy: 76.11217% ===\n"
     ]
    }
   ],
   "source": [
    "# Defines a function that takes a given DataFrame, splits the data into testing and training sets then applies Linear Regression.\n",
    "\n",
    "def train(data):\n",
    "    \n",
    "    # Sets the subject and target DataFrames. \n",
    "    \n",
    "    dataIn = data.drop(columns=['popularity'])\n",
    "    dataOut = data['popularity']\n",
    "\n",
    "    dataInTrain, dataInTest, dataOutTrain, dataOutTest = train_test_split(dataIn, dataOut, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(dataInTrain, dataOutTrain)\n",
    "\n",
    "    predictions = model.predict(dataInTest)\n",
    "    \n",
    "    print(\"MSE: \" + str(mean_squared_error(dataOutTest, predictions)))\n",
    "\n",
    "    print(\"R^2: \" + str(r2_score(dataOutTest, predictions)))\n",
    "\n",
    "    accuracy = model.score(dataInTest, dataOutTest)\n",
    "    \n",
    "    print(\"Accuracy: {:.5f}%\\n\".format(accuracy * 100))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "print(\"=== Baseline Accuracy: {:.5f}% ===\".format((train(baselineDf)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just from this initial basline we can see that the accuracy is 76.11217% accurate at predicting the popularity of a song based on it's characteristics.\n",
    "\n",
    "Let's see if we can improve this by adjusting the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting The Dataset\n",
    "\n",
    "The first thing I want to try is to add artists to the training model. As some artists may be so popular that it is likley that when they release a song it is going to have a high popularity score.\n",
    "\n",
    "To achieve this I have decided to use a LabelEncoder to convert the arrays of artists names to a unique Integer value so it can be trained in the model alongside the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 113.67924490171757\n",
      "R^2: 0.7612616085739821\n",
      "Accuracy: 76.12616%\n",
      "\n",
      "=== Artist Adjustment Accuracy: 76.12616% ===\n"
     ]
    }
   ],
   "source": [
    "# Imports sklearn's LabelEncoder library.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Creates a new DataFrame for the adjustments.\n",
    "\n",
    "adjustmentDf = df.drop(columns=['id', 'release_date', 'name', 'mode']).copy()\n",
    "\n",
    "# A function to apply the artists adjustment to a DataFrame.\n",
    "\n",
    "def encodeStrings(data, column):\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(data[column].astype('str'))\n",
    "\n",
    "# Applies function to the artists column.\n",
    "\n",
    "adjustmentDf['artists'] = encodeStrings(adjustmentDf, 'artists')\n",
    "\n",
    "# Trains the new adjustment DataFrame and outputs the results.\n",
    "\n",
    "print(\"=== Artist Adjustment Accuracy: {:.5f}% ===\".format((train(adjustmentDf)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this small improvement we can see a gain of 0.01399% in accuracy. Not the greatest improvement, but improvement nonetheless.\n",
    "\n",
    "Next I want to modify the dataframe even further, this time by applying a function to some of the columns to generalise the data to make matches more likley.\n",
    "\n",
    "I am going to define two functions:\n",
    "\n",
    "normaliseMetrics : Rounds the given column's value's to two decimal places.\n",
    "\n",
    "normaliseTempo: Rounds the tempo column's value's to the nearest ten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to round a given column's value's to two decimal places.\n",
    "\n",
    "def normaliseMetrics(value):\n",
    "    return round(value, 2)\n",
    "\n",
    "# Function to round the tempo column's value's to the nearest ten.\n",
    "\n",
    "def normaliseTempo(value):\n",
    "    return round(abs(value), -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now apply these modifier functions to the relevent columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.98</td>\n",
       "      <td>26839</td>\n",
       "      <td>0.28</td>\n",
       "      <td>831667</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-20.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.96</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7382</td>\n",
       "      <td>0.82</td>\n",
       "      <td>180533</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-12.44</td>\n",
       "      <td>5</td>\n",
       "      <td>0.41</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.96</td>\n",
       "      <td>16378</td>\n",
       "      <td>0.33</td>\n",
       "      <td>500062</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-14.85</td>\n",
       "      <td>5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.17</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10077</td>\n",
       "      <td>0.28</td>\n",
       "      <td>210000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-9.32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.96</td>\n",
       "      <td>23719</td>\n",
       "      <td>0.42</td>\n",
       "      <td>166693</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-10.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence  year  acousticness  artists  danceability  duration_ms  energy  \\\n",
       "0     0.06  1921          0.98    26839          0.28       831667    0.21   \n",
       "1     0.96  1921          0.73     7382          0.82       180533    0.34   \n",
       "2     0.04  1921          0.96    16378          0.33       500062    0.17   \n",
       "3     0.17  1921          0.97    10077          0.28       210000    0.31   \n",
       "4     0.25  1921          0.96    23719          0.42       166693    0.19   \n",
       "\n",
       "   explicit  instrumentalness  key  liveness  loudness  popularity  \\\n",
       "0         0              0.88   10      0.67    -20.10           4   \n",
       "1         0              0.00    7      0.16    -12.44           5   \n",
       "2         0              0.91    3      0.10    -14.85           5   \n",
       "3         0              0.00    5      0.38     -9.32           3   \n",
       "4         0              0.00    3      0.23    -10.10           2   \n",
       "\n",
       "   speechiness  tempo  \n",
       "0         0.04   80.0  \n",
       "1         0.41   60.0  \n",
       "2         0.03  110.0  \n",
       "3         0.04  100.0  \n",
       "4         0.04  100.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies the normaliseMetrics function to each of the following columns.\n",
    "\n",
    "adjustmentDf['valence'] = adjustmentDf['valence'].apply(normaliseMetrics)\n",
    "adjustmentDf['acousticness'] = adjustmentDf['acousticness'].apply(normaliseMetrics)\n",
    "adjustmentDf['danceability'] = adjustmentDf['danceability'].apply(normaliseMetrics)\n",
    "adjustmentDf['energy'] = adjustmentDf['energy'].apply(normaliseMetrics)\n",
    "adjustmentDf['instrumentalness'] = adjustmentDf['instrumentalness'].apply(normaliseMetrics)\n",
    "adjustmentDf['liveness'] = adjustmentDf['liveness'].apply(normaliseMetrics)\n",
    "adjustmentDf['loudness'] = adjustmentDf['loudness'].apply(normaliseMetrics)\n",
    "adjustmentDf['speechiness'] = adjustmentDf['speechiness'].apply(normaliseMetrics)\n",
    "\n",
    "# Applies the normaliseMetrics function to the tempo column.\n",
    "\n",
    "adjustmentDf['tempo'] = adjustmentDf['tempo'].apply(normaliseTempo)\n",
    "\n",
    "adjustmentDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the dataframe has now had each of the relevent columns modified to make the data more general.\n",
    "\n",
    "Now we can run the updated dataframe though the training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 113.68077577361474\n",
      "R^2: 0.7612583935817069\n",
      "Accuracy: 76.12584%\n",
      "\n",
      "=== Adjustment Average Accuracy: 76.12584% ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Adjustment Average Accuracy: {:.5f}% ===\".format((train(adjustmentDf)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out this adjustment has actually decreased the accuracy by -0.00032%, proving that the regression works as effectivly even if the data is more general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres\n",
    "\n",
    "Next up I will now use the data_w_genres.csv dataset to provide each song in the existing data.csv dataset with the genres associated with each accredited artist. \n",
    "\n",
    "If we take a look at: Lana Del Rey, Royal Blood and Bill Withers as an example artists, we can see their associated genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>artists</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14100</th>\n",
       "      <td>['art pop', 'pop']</td>\n",
       "      <td>Lana Del Rey</td>\n",
       "      <td>0.44669</td>\n",
       "      <td>0.423221</td>\n",
       "      <td>256964.019608</td>\n",
       "      <td>0.542764</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.17142</td>\n",
       "      <td>-8.448186</td>\n",
       "      <td>0.055098</td>\n",
       "      <td>115.393554</td>\n",
       "      <td>0.254493</td>\n",
       "      <td>57.892157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   genres       artists  acousticness  danceability  \\\n",
       "14100  ['art pop', 'pop']  Lana Del Rey       0.44669      0.423221   \n",
       "\n",
       "         duration_ms    energy  instrumentalness  liveness  loudness  \\\n",
       "14100  256964.019608  0.542764          0.020926   0.17142 -8.448186   \n",
       "\n",
       "       speechiness       tempo   valence  popularity  key  mode  count  \n",
       "14100     0.055098  115.393554  0.254493   57.892157    0     0    204  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the data_w_genres.csv as a new DataFrame.\n",
    "\n",
    "genresDf = pd.read_csv('data_w_genres.csv')\n",
    "\n",
    "genresDf.loc[genresDf['artists'] ==  \"Lana Del Rey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>artists</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21432</th>\n",
       "      <td>['brighton indie', 'garage rock', 'modern alte...</td>\n",
       "      <td>Royal Blood</td>\n",
       "      <td>0.04634</td>\n",
       "      <td>0.5242</td>\n",
       "      <td>212152.8</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>0.15664</td>\n",
       "      <td>-4.4422</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>107.982</td>\n",
       "      <td>0.5894</td>\n",
       "      <td>54.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  genres      artists  \\\n",
       "21432  ['brighton indie', 'garage rock', 'modern alte...  Royal Blood   \n",
       "\n",
       "       acousticness  danceability  duration_ms  energy  instrumentalness  \\\n",
       "21432       0.04634        0.5242     212152.8   0.876           0.00208   \n",
       "\n",
       "       liveness  loudness  speechiness    tempo  valence  popularity  key  \\\n",
       "21432   0.15664   -4.4422       0.0574  107.982   0.5894        54.6    0   \n",
       "\n",
       "       mode  count  \n",
       "21432     1     10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genresDf.loc[genresDf['artists'] ==  \"Royal Blood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>artists</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>['funk', 'motown', 'quiet storm', 'soul']</td>\n",
       "      <td>Bill Withers</td>\n",
       "      <td>0.471254</td>\n",
       "      <td>0.653619</td>\n",
       "      <td>257137.321429</td>\n",
       "      <td>0.468529</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>-12.269083</td>\n",
       "      <td>0.064256</td>\n",
       "      <td>111.738393</td>\n",
       "      <td>0.629061</td>\n",
       "      <td>40.52381</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         genres       artists  acousticness  \\\n",
       "2701  ['funk', 'motown', 'quiet storm', 'soul']  Bill Withers      0.471254   \n",
       "\n",
       "      danceability    duration_ms    energy  instrumentalness  liveness  \\\n",
       "2701      0.653619  257137.321429  0.468529          0.065161  0.209877   \n",
       "\n",
       "       loudness  speechiness       tempo   valence  popularity  key  mode  \\\n",
       "2701 -12.269083     0.064256  111.738393  0.629061    40.52381    9     1   \n",
       "\n",
       "      count  \n",
       "2701    168  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genresDf.loc[genresDf['artists'] ==  \"Bill Withers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will iterate over each song in the data.csv dataset and for each of the accredited artists will lookup in the data_w_genres.csv dataset what the genres are for the given artist. Then export the new dataset as a csv called: songs_w_genres.csv\n",
    "\n",
    "#### Warning: \n",
    "\n",
    "This process requires a lot of data processing and will be an intensive task on your computer. It took my 2020 MacBook Pro with a 2.3 GHz Quad-Core Intel Core i7 and 16 GB of Memory over 25 minutes at 100% CPU to process this. So if you don't wish to run this I have provided an already processed songs_w_genres.csv in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 1 of 170653\n",
      "Parsed 2 of 170653\n",
      "Parsed 3 of 170653\n",
      "Parsed 4 of 170653\n",
      "Parsed 5 of 170653\n",
      "Parsed 6 of 170653\n",
      "Parsed 7 of 170653\n",
      "Parsed 8 of 170653\n",
      "Parsed 9 of 170653\n",
      "Parsed 10 of 170653\n",
      "Parsed 11 of 170653\n",
      "Parsed 12 of 170653\n",
      "Parsed 13 of 170653\n",
      "Parsed 14 of 170653\n",
      "Parsed 15 of 170653\n",
      "Parsed 16 of 170653\n",
      "Parsed 17 of 170653\n",
      "Parsed 18 of 170653\n",
      "Parsed 19 of 170653\n",
      "Parsed 20 of 170653\n",
      "Parsed 21 of 170653\n",
      "Parsed 22 of 170653\n",
      "Parsed 23 of 170653\n",
      "Parsed 24 of 170653\n",
      "Parsed 25 of 170653\n",
      "Parsed 26 of 170653\n",
      "Parsed 27 of 170653\n",
      "Parsed 28 of 170653\n",
      "Parsed 29 of 170653\n",
      "Parsed 30 of 170653\n",
      "Parsed 31 of 170653\n",
      "Parsed 32 of 170653\n",
      "Parsed 33 of 170653\n",
      "Parsed 34 of 170653\n",
      "Parsed 35 of 170653\n",
      "Parsed 36 of 170653\n",
      "Parsed 37 of 170653\n",
      "Parsed 38 of 170653\n",
      "Parsed 39 of 170653\n",
      "Parsed 40 of 170653\n",
      "Parsed 41 of 170653\n",
      "Parsed 42 of 170653\n",
      "Parsed 43 of 170653\n",
      "Parsed 44 of 170653\n",
      "Parsed 45 of 170653\n",
      "Parsed 46 of 170653\n",
      "Parsed 47 of 170653\n",
      "Parsed 48 of 170653\n",
      "Parsed 49 of 170653\n",
      "Parsed 50 of 170653\n",
      "Parsed 51 of 170653\n",
      "Parsed 52 of 170653\n",
      "Parsed 53 of 170653\n",
      "Parsed 54 of 170653\n",
      "Parsed 55 of 170653\n",
      "Parsed 56 of 170653\n",
      "Parsed 57 of 170653\n",
      "Parsed 58 of 170653\n",
      "Parsed 59 of 170653\n",
      "Parsed 60 of 170653\n",
      "Parsed 61 of 170653\n",
      "Parsed 62 of 170653\n",
      "Parsed 63 of 170653\n",
      "Parsed 64 of 170653\n",
      "Parsed 65 of 170653\n",
      "Parsed 66 of 170653\n",
      "Parsed 67 of 170653\n",
      "Parsed 68 of 170653\n",
      "Parsed 69 of 170653\n",
      "Parsed 70 of 170653\n",
      "Parsed 71 of 170653\n",
      "Parsed 72 of 170653\n",
      "Parsed 73 of 170653\n",
      "Parsed 74 of 170653\n",
      "Parsed 75 of 170653\n",
      "Parsed 76 of 170653\n",
      "Parsed 77 of 170653\n",
      "Parsed 78 of 170653\n",
      "Parsed 79 of 170653\n",
      "Parsed 80 of 170653\n",
      "Parsed 81 of 170653\n",
      "Parsed 82 of 170653\n",
      "Parsed 83 of 170653\n",
      "Parsed 84 of 170653\n",
      "Parsed 85 of 170653\n",
      "Parsed 86 of 170653\n",
      "Parsed 87 of 170653\n",
      "Parsed 88 of 170653\n",
      "Parsed 89 of 170653\n",
      "Parsed 90 of 170653\n",
      "Parsed 91 of 170653\n",
      "Parsed 92 of 170653\n",
      "Parsed 93 of 170653\n",
      "Parsed 94 of 170653\n",
      "Parsed 95 of 170653\n",
      "Parsed 96 of 170653\n",
      "Parsed 97 of 170653\n",
      "Parsed 98 of 170653\n",
      "Parsed 99 of 170653\n",
      "Parsed 100 of 170653\n",
      "Parsed 101 of 170653\n",
      "Parsed 102 of 170653\n",
      "Parsed 103 of 170653\n",
      "Parsed 104 of 170653\n",
      "Parsed 105 of 170653\n",
      "Parsed 106 of 170653\n",
      "Parsed 107 of 170653\n",
      "Parsed 108 of 170653\n",
      "Parsed 109 of 170653\n",
      "Parsed 110 of 170653\n",
      "Parsed 111 of 170653\n",
      "Parsed 112 of 170653\n",
      "Parsed 113 of 170653\n",
      "Parsed 114 of 170653\n",
      "Parsed 115 of 170653\n",
      "Parsed 116 of 170653\n",
      "Parsed 117 of 170653\n",
      "Parsed 118 of 170653\n",
      "Parsed 119 of 170653\n",
      "Parsed 120 of 170653\n",
      "Parsed 121 of 170653\n",
      "Parsed 122 of 170653\n",
      "Parsed 123 of 170653\n",
      "Parsed 124 of 170653\n",
      "Parsed 125 of 170653\n",
      "Parsed 126 of 170653\n",
      "Parsed 127 of 170653\n",
      "Parsed 128 of 170653\n",
      "Parsed 129 of 170653\n",
      "Parsed 130 of 170653\n",
      "Parsed 131 of 170653\n",
      "Parsed 132 of 170653\n",
      "Parsed 133 of 170653\n",
      "Parsed 134 of 170653\n",
      "Parsed 135 of 170653\n",
      "Parsed 136 of 170653\n",
      "Parsed 137 of 170653\n",
      "Parsed 138 of 170653\n",
      "Parsed 139 of 170653\n",
      "Parsed 140 of 170653\n",
      "Parsed 141 of 170653\n",
      "Parsed 142 of 170653\n",
      "Parsed 143 of 170653\n",
      "Parsed 144 of 170653\n",
      "Parsed 145 of 170653\n",
      "Parsed 146 of 170653\n",
      "Parsed 147 of 170653\n",
      "Parsed 148 of 170653\n",
      "Parsed 149 of 170653\n",
      "Parsed 150 of 170653\n",
      "Parsed 151 of 170653\n",
      "Parsed 152 of 170653\n",
      "Parsed 153 of 170653\n",
      "Parsed 154 of 170653\n",
      "Parsed 155 of 170653\n",
      "Parsed 156 of 170653\n",
      "Parsed 157 of 170653\n",
      "Parsed 158 of 170653\n",
      "Parsed 159 of 170653\n",
      "Parsed 160 of 170653\n",
      "Parsed 161 of 170653\n",
      "Parsed 162 of 170653\n",
      "Parsed 163 of 170653\n",
      "Parsed 164 of 170653\n",
      "Parsed 165 of 170653\n",
      "Parsed 166 of 170653\n",
      "Parsed 167 of 170653\n",
      "Parsed 168 of 170653\n",
      "Parsed 169 of 170653\n",
      "Parsed 170 of 170653\n",
      "Parsed 171 of 170653\n",
      "Parsed 172 of 170653\n",
      "Parsed 173 of 170653\n",
      "Parsed 174 of 170653\n",
      "Parsed 175 of 170653\n",
      "Parsed 176 of 170653\n",
      "Parsed 177 of 170653\n",
      "Parsed 178 of 170653\n",
      "Parsed 179 of 170653\n",
      "Parsed 180 of 170653\n",
      "Parsed 181 of 170653\n",
      "Parsed 182 of 170653\n",
      "Parsed 183 of 170653\n",
      "Parsed 184 of 170653\n",
      "Parsed 185 of 170653\n",
      "Parsed 186 of 170653\n",
      "Parsed 187 of 170653\n",
      "Parsed 188 of 170653\n",
      "Parsed 189 of 170653\n",
      "Parsed 190 of 170653\n",
      "Parsed 191 of 170653\n",
      "Parsed 192 of 170653\n",
      "Parsed 193 of 170653\n",
      "Parsed 194 of 170653\n",
      "Parsed 195 of 170653\n",
      "Parsed 196 of 170653\n",
      "Parsed 197 of 170653\n",
      "Parsed 198 of 170653\n",
      "Parsed 199 of 170653\n",
      "Parsed 200 of 170653\n",
      "Parsed 201 of 170653\n",
      "Parsed 202 of 170653\n",
      "Parsed 203 of 170653\n",
      "Parsed 204 of 170653\n",
      "Parsed 205 of 170653\n",
      "Parsed 206 of 170653\n",
      "Parsed 207 of 170653\n",
      "Parsed 208 of 170653\n",
      "Parsed 209 of 170653\n",
      "Parsed 210 of 170653\n",
      "Parsed 211 of 170653\n",
      "Parsed 212 of 170653\n",
      "Parsed 213 of 170653\n",
      "Parsed 214 of 170653\n",
      "Parsed 215 of 170653\n",
      "Parsed 216 of 170653\n",
      "Parsed 217 of 170653\n",
      "Parsed 218 of 170653\n",
      "Parsed 219 of 170653\n",
      "Parsed 220 of 170653\n",
      "Parsed 221 of 170653\n",
      "Parsed 222 of 170653\n",
      "Parsed 223 of 170653\n",
      "Parsed 224 of 170653\n",
      "Parsed 225 of 170653\n",
      "Parsed 226 of 170653\n",
      "Parsed 227 of 170653\n",
      "Parsed 228 of 170653\n",
      "Parsed 229 of 170653\n",
      "Parsed 230 of 170653\n",
      "Parsed 231 of 170653\n",
      "Parsed 232 of 170653\n",
      "Parsed 233 of 170653\n",
      "Parsed 234 of 170653\n",
      "Parsed 235 of 170653\n",
      "Parsed 236 of 170653\n",
      "Parsed 237 of 170653\n",
      "Parsed 238 of 170653\n",
      "Parsed 239 of 170653\n",
      "Parsed 240 of 170653\n",
      "Parsed 241 of 170653\n",
      "Parsed 242 of 170653\n",
      "Parsed 243 of 170653\n",
      "Parsed 244 of 170653\n",
      "Parsed 245 of 170653\n",
      "Parsed 246 of 170653\n",
      "Parsed 247 of 170653\n",
      "Parsed 248 of 170653\n",
      "Parsed 249 of 170653\n",
      "Parsed 250 of 170653\n",
      "Parsed 251 of 170653\n",
      "Parsed 252 of 170653\n",
      "Parsed 253 of 170653\n",
      "Parsed 254 of 170653\n",
      "Parsed 255 of 170653\n",
      "Parsed 256 of 170653\n",
      "Parsed 257 of 170653\n",
      "Parsed 258 of 170653\n",
      "Parsed 259 of 170653\n",
      "Parsed 260 of 170653\n",
      "Parsed 261 of 170653\n",
      "Parsed 262 of 170653\n",
      "Parsed 263 of 170653\n",
      "Parsed 264 of 170653\n",
      "Parsed 265 of 170653\n",
      "Parsed 266 of 170653\n",
      "Parsed 267 of 170653\n",
      "Parsed 268 of 170653\n",
      "Parsed 269 of 170653\n",
      "Parsed 270 of 170653\n",
      "Parsed 271 of 170653\n",
      "Parsed 272 of 170653\n",
      "Parsed 273 of 170653\n",
      "Parsed 274 of 170653\n",
      "Parsed 275 of 170653\n",
      "Parsed 276 of 170653\n",
      "Parsed 277 of 170653\n",
      "Parsed 278 of 170653\n",
      "Parsed 279 of 170653\n",
      "Parsed 280 of 170653\n",
      "Parsed 281 of 170653\n",
      "Parsed 282 of 170653\n",
      "Parsed 283 of 170653\n",
      "Parsed 284 of 170653\n",
      "Parsed 285 of 170653\n",
      "Parsed 286 of 170653\n",
      "Parsed 287 of 170653\n",
      "Parsed 288 of 170653\n",
      "Parsed 289 of 170653\n",
      "Parsed 290 of 170653\n",
      "Parsed 291 of 170653\n",
      "Parsed 292 of 170653\n",
      "Parsed 293 of 170653\n",
      "Parsed 294 of 170653\n",
      "Parsed 295 of 170653\n",
      "Parsed 296 of 170653\n",
      "Parsed 297 of 170653\n",
      "Parsed 298 of 170653\n",
      "Parsed 299 of 170653\n",
      "Parsed 300 of 170653\n",
      "Parsed 301 of 170653\n",
      "Parsed 302 of 170653\n",
      "Parsed 303 of 170653\n",
      "Parsed 304 of 170653\n",
      "Parsed 305 of 170653\n",
      "Parsed 306 of 170653\n",
      "Parsed 307 of 170653\n",
      "Parsed 308 of 170653\n",
      "Parsed 309 of 170653\n",
      "Parsed 310 of 170653\n",
      "Parsed 311 of 170653\n",
      "Parsed 312 of 170653\n",
      "Parsed 313 of 170653\n",
      "Parsed 314 of 170653\n",
      "Parsed 315 of 170653\n",
      "Parsed 316 of 170653\n",
      "Parsed 317 of 170653\n",
      "Parsed 318 of 170653\n",
      "Parsed 319 of 170653\n",
      "Parsed 320 of 170653\n",
      "Parsed 321 of 170653\n",
      "Parsed 322 of 170653\n",
      "Parsed 323 of 170653\n",
      "Parsed 324 of 170653\n",
      "Parsed 325 of 170653\n",
      "Parsed 326 of 170653\n",
      "Parsed 327 of 170653\n",
      "Parsed 328 of 170653\n",
      "Parsed 329 of 170653\n",
      "Parsed 330 of 170653\n",
      "Parsed 331 of 170653\n",
      "Parsed 332 of 170653\n",
      "Parsed 333 of 170653\n",
      "Parsed 334 of 170653\n",
      "Parsed 335 of 170653\n",
      "Parsed 336 of 170653\n",
      "Parsed 337 of 170653\n",
      "Parsed 338 of 170653\n",
      "Parsed 339 of 170653\n",
      "Parsed 340 of 170653\n",
      "Parsed 341 of 170653\n",
      "Parsed 342 of 170653\n",
      "Parsed 343 of 170653\n",
      "Parsed 344 of 170653\n",
      "Parsed 345 of 170653\n",
      "Parsed 346 of 170653\n",
      "Parsed 347 of 170653\n",
      "Parsed 348 of 170653\n",
      "Parsed 349 of 170653\n",
      "Parsed 350 of 170653\n",
      "Parsed 351 of 170653\n",
      "Parsed 352 of 170653\n",
      "Parsed 353 of 170653\n",
      "Parsed 354 of 170653\n",
      "Parsed 355 of 170653\n",
      "Parsed 356 of 170653\n",
      "Parsed 357 of 170653\n",
      "Parsed 358 of 170653\n",
      "Parsed 359 of 170653\n",
      "Parsed 360 of 170653\n",
      "Parsed 361 of 170653\n",
      "Parsed 362 of 170653\n",
      "Parsed 363 of 170653\n",
      "Parsed 364 of 170653\n",
      "Parsed 365 of 170653\n",
      "Parsed 366 of 170653\n",
      "Parsed 367 of 170653\n",
      "Parsed 368 of 170653\n",
      "Parsed 369 of 170653\n",
      "Parsed 370 of 170653\n",
      "Parsed 371 of 170653\n",
      "Parsed 372 of 170653\n",
      "Parsed 373 of 170653\n",
      "Parsed 374 of 170653\n",
      "Parsed 375 of 170653\n",
      "Parsed 376 of 170653\n",
      "Parsed 377 of 170653\n",
      "Parsed 378 of 170653\n",
      "Parsed 379 of 170653\n",
      "Parsed 380 of 170653\n",
      "Parsed 381 of 170653\n",
      "Parsed 382 of 170653\n",
      "Parsed 383 of 170653\n",
      "Parsed 384 of 170653\n",
      "Parsed 385 of 170653\n",
      "Parsed 386 of 170653\n",
      "Parsed 387 of 170653\n",
      "Parsed 388 of 170653\n",
      "Parsed 389 of 170653\n",
      "Parsed 390 of 170653\n",
      "Parsed 391 of 170653\n",
      "Parsed 392 of 170653\n",
      "Parsed 393 of 170653\n",
      "Parsed 394 of 170653\n",
      "Parsed 395 of 170653\n",
      "Parsed 396 of 170653\n",
      "Parsed 397 of 170653\n",
      "Parsed 398 of 170653\n",
      "Parsed 399 of 170653\n",
      "Parsed 400 of 170653\n",
      "Parsed 401 of 170653\n",
      "Parsed 402 of 170653\n",
      "Parsed 403 of 170653\n",
      "Parsed 404 of 170653\n",
      "Parsed 405 of 170653\n",
      "Parsed 406 of 170653\n",
      "Parsed 407 of 170653\n",
      "Parsed 408 of 170653\n",
      "Parsed 409 of 170653\n",
      "Parsed 410 of 170653\n",
      "Parsed 411 of 170653\n",
      "Parsed 412 of 170653\n",
      "Parsed 413 of 170653\n",
      "Parsed 414 of 170653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 415 of 170653\n",
      "Parsed 416 of 170653\n",
      "Parsed 417 of 170653\n",
      "Parsed 418 of 170653\n",
      "Parsed 419 of 170653\n",
      "Parsed 420 of 170653\n",
      "Parsed 421 of 170653\n",
      "Parsed 422 of 170653\n",
      "Parsed 423 of 170653\n",
      "Parsed 424 of 170653\n",
      "Parsed 425 of 170653\n",
      "Parsed 426 of 170653\n",
      "Parsed 427 of 170653\n",
      "Parsed 428 of 170653\n",
      "Parsed 429 of 170653\n",
      "Parsed 430 of 170653\n",
      "Parsed 431 of 170653\n",
      "Parsed 432 of 170653\n",
      "Parsed 433 of 170653\n",
      "Parsed 434 of 170653\n",
      "Parsed 435 of 170653\n",
      "Parsed 436 of 170653\n",
      "Parsed 437 of 170653\n",
      "Parsed 438 of 170653\n",
      "Parsed 439 of 170653\n",
      "Parsed 440 of 170653\n",
      "Parsed 441 of 170653\n",
      "Parsed 442 of 170653\n",
      "Parsed 443 of 170653\n",
      "Parsed 444 of 170653\n",
      "Parsed 445 of 170653\n",
      "Parsed 446 of 170653\n",
      "Parsed 447 of 170653\n",
      "Parsed 448 of 170653\n",
      "Parsed 449 of 170653\n",
      "Parsed 450 of 170653\n",
      "Parsed 451 of 170653\n",
      "Parsed 452 of 170653\n",
      "Parsed 453 of 170653\n",
      "Parsed 454 of 170653\n",
      "Parsed 455 of 170653\n",
      "Parsed 456 of 170653\n",
      "Parsed 457 of 170653\n",
      "Parsed 458 of 170653\n",
      "Parsed 459 of 170653\n",
      "Parsed 460 of 170653\n",
      "Parsed 461 of 170653\n",
      "Parsed 462 of 170653\n",
      "Parsed 463 of 170653\n",
      "Parsed 464 of 170653\n",
      "Parsed 465 of 170653\n",
      "Parsed 466 of 170653\n",
      "Parsed 467 of 170653\n",
      "Parsed 468 of 170653\n",
      "Parsed 469 of 170653\n",
      "Parsed 470 of 170653\n",
      "Parsed 471 of 170653\n",
      "Parsed 472 of 170653\n",
      "Parsed 473 of 170653\n",
      "Parsed 474 of 170653\n",
      "Parsed 475 of 170653\n",
      "Parsed 476 of 170653\n",
      "Parsed 477 of 170653\n",
      "Parsed 478 of 170653\n",
      "Parsed 479 of 170653\n",
      "Parsed 480 of 170653\n",
      "Parsed 481 of 170653\n",
      "Parsed 482 of 170653\n",
      "Parsed 483 of 170653\n",
      "Parsed 484 of 170653\n",
      "Parsed 485 of 170653\n",
      "Parsed 486 of 170653\n",
      "Parsed 487 of 170653\n",
      "Parsed 488 of 170653\n",
      "Parsed 489 of 170653\n",
      "Parsed 490 of 170653\n",
      "Parsed 491 of 170653\n",
      "Parsed 492 of 170653\n",
      "Parsed 493 of 170653\n",
      "Parsed 494 of 170653\n",
      "Parsed 495 of 170653\n",
      "Parsed 496 of 170653\n",
      "Parsed 497 of 170653\n",
      "Parsed 498 of 170653\n",
      "Parsed 499 of 170653\n",
      "Parsed 500 of 170653\n",
      "Parsed 501 of 170653\n",
      "Parsed 502 of 170653\n",
      "Parsed 503 of 170653\n",
      "Parsed 504 of 170653\n",
      "Parsed 505 of 170653\n",
      "Parsed 506 of 170653\n",
      "Parsed 507 of 170653\n",
      "Parsed 508 of 170653\n",
      "Parsed 509 of 170653\n",
      "Parsed 510 of 170653\n",
      "Parsed 511 of 170653\n",
      "Parsed 512 of 170653\n",
      "Parsed 513 of 170653\n",
      "Parsed 514 of 170653\n",
      "Parsed 515 of 170653\n",
      "Parsed 516 of 170653\n",
      "Parsed 517 of 170653\n",
      "Parsed 518 of 170653\n",
      "Parsed 519 of 170653\n",
      "Parsed 520 of 170653\n",
      "Parsed 521 of 170653\n",
      "Parsed 522 of 170653\n",
      "Parsed 523 of 170653\n",
      "Parsed 524 of 170653\n",
      "Parsed 525 of 170653\n",
      "Parsed 526 of 170653\n",
      "Parsed 527 of 170653\n",
      "Parsed 528 of 170653\n",
      "Parsed 529 of 170653\n",
      "Parsed 530 of 170653\n",
      "Parsed 531 of 170653\n",
      "Parsed 532 of 170653\n",
      "Parsed 533 of 170653\n",
      "Parsed 534 of 170653\n",
      "Parsed 535 of 170653\n",
      "Parsed 536 of 170653\n",
      "Parsed 537 of 170653\n",
      "Parsed 538 of 170653\n",
      "Parsed 539 of 170653\n",
      "Parsed 540 of 170653\n",
      "Parsed 541 of 170653\n",
      "Parsed 542 of 170653\n",
      "Parsed 543 of 170653\n",
      "Parsed 544 of 170653\n",
      "Parsed 545 of 170653\n",
      "Parsed 546 of 170653\n",
      "Parsed 547 of 170653\n",
      "Parsed 548 of 170653\n",
      "Parsed 549 of 170653\n",
      "Parsed 550 of 170653\n",
      "Parsed 551 of 170653\n",
      "Parsed 552 of 170653\n",
      "Parsed 553 of 170653\n",
      "Parsed 554 of 170653\n",
      "Parsed 555 of 170653\n",
      "Parsed 556 of 170653\n",
      "Parsed 557 of 170653\n",
      "Parsed 558 of 170653\n",
      "Parsed 559 of 170653\n",
      "Parsed 560 of 170653\n",
      "Parsed 561 of 170653\n",
      "Parsed 562 of 170653\n",
      "Parsed 563 of 170653\n",
      "Parsed 564 of 170653\n",
      "Parsed 565 of 170653\n",
      "Parsed 566 of 170653\n",
      "Parsed 567 of 170653\n",
      "Parsed 568 of 170653\n",
      "Parsed 569 of 170653\n",
      "Parsed 570 of 170653\n",
      "Parsed 571 of 170653\n",
      "Parsed 572 of 170653\n",
      "Parsed 573 of 170653\n",
      "Parsed 574 of 170653\n",
      "Parsed 575 of 170653\n",
      "Parsed 576 of 170653\n",
      "Parsed 577 of 170653\n",
      "Parsed 578 of 170653\n",
      "Parsed 579 of 170653\n",
      "Parsed 580 of 170653\n",
      "Parsed 581 of 170653\n",
      "Parsed 582 of 170653\n",
      "Parsed 583 of 170653\n",
      "Parsed 584 of 170653\n",
      "Parsed 585 of 170653\n",
      "Parsed 586 of 170653\n",
      "Parsed 587 of 170653\n",
      "Parsed 588 of 170653\n",
      "Parsed 589 of 170653\n",
      "Parsed 590 of 170653\n",
      "Parsed 591 of 170653\n",
      "Parsed 592 of 170653\n",
      "Parsed 593 of 170653\n",
      "Parsed 594 of 170653\n",
      "Parsed 595 of 170653\n",
      "Parsed 596 of 170653\n",
      "Parsed 597 of 170653\n",
      "Parsed 598 of 170653\n",
      "Parsed 599 of 170653\n",
      "Parsed 600 of 170653\n",
      "Parsed 601 of 170653\n",
      "Parsed 602 of 170653\n",
      "Parsed 603 of 170653\n",
      "Parsed 604 of 170653\n",
      "Parsed 605 of 170653\n",
      "Parsed 606 of 170653\n",
      "Parsed 607 of 170653\n",
      "Parsed 608 of 170653\n",
      "Parsed 609 of 170653\n",
      "Parsed 610 of 170653\n",
      "Parsed 611 of 170653\n",
      "Parsed 612 of 170653\n",
      "Parsed 613 of 170653\n",
      "Parsed 614 of 170653\n",
      "Parsed 615 of 170653\n",
      "Parsed 616 of 170653\n",
      "Parsed 617 of 170653\n",
      "Parsed 618 of 170653\n",
      "Parsed 619 of 170653\n",
      "Parsed 620 of 170653\n",
      "Parsed 621 of 170653\n",
      "Parsed 622 of 170653\n",
      "Parsed 623 of 170653\n",
      "Parsed 624 of 170653\n",
      "Parsed 625 of 170653\n",
      "Parsed 626 of 170653\n",
      "Parsed 627 of 170653\n",
      "Parsed 628 of 170653\n",
      "Parsed 629 of 170653\n",
      "Parsed 630 of 170653\n",
      "Parsed 631 of 170653\n",
      "Parsed 632 of 170653\n",
      "Parsed 633 of 170653\n",
      "Parsed 634 of 170653\n",
      "Parsed 635 of 170653\n",
      "Parsed 636 of 170653\n",
      "Parsed 637 of 170653\n",
      "Parsed 638 of 170653\n",
      "Parsed 639 of 170653\n",
      "Parsed 640 of 170653\n",
      "Parsed 641 of 170653\n",
      "Parsed 642 of 170653\n",
      "Parsed 643 of 170653\n",
      "Parsed 644 of 170653\n",
      "Parsed 645 of 170653\n",
      "Parsed 646 of 170653\n",
      "Parsed 647 of 170653\n",
      "Parsed 648 of 170653\n",
      "Parsed 649 of 170653\n",
      "Parsed 650 of 170653\n",
      "Parsed 651 of 170653\n",
      "Parsed 652 of 170653\n",
      "Parsed 653 of 170653\n",
      "Parsed 654 of 170653\n",
      "Parsed 655 of 170653\n",
      "Parsed 656 of 170653\n",
      "Parsed 657 of 170653\n",
      "Parsed 658 of 170653\n",
      "Parsed 659 of 170653\n",
      "Parsed 660 of 170653\n",
      "Parsed 661 of 170653\n",
      "Parsed 662 of 170653\n",
      "Parsed 663 of 170653\n",
      "Parsed 664 of 170653\n",
      "Parsed 665 of 170653\n",
      "Parsed 666 of 170653\n",
      "Parsed 667 of 170653\n",
      "Parsed 668 of 170653\n",
      "Parsed 669 of 170653\n",
      "Parsed 670 of 170653\n",
      "Parsed 671 of 170653\n",
      "Parsed 672 of 170653\n",
      "Parsed 673 of 170653\n",
      "Parsed 674 of 170653\n",
      "Parsed 675 of 170653\n",
      "Parsed 676 of 170653\n",
      "Parsed 677 of 170653\n",
      "Parsed 678 of 170653\n",
      "Parsed 679 of 170653\n",
      "Parsed 680 of 170653\n",
      "Parsed 681 of 170653\n",
      "Parsed 682 of 170653\n",
      "Parsed 683 of 170653\n",
      "Parsed 684 of 170653\n",
      "Parsed 685 of 170653\n",
      "Parsed 686 of 170653\n",
      "Parsed 687 of 170653\n",
      "Parsed 688 of 170653\n",
      "Parsed 689 of 170653\n",
      "Parsed 690 of 170653\n",
      "Parsed 691 of 170653\n",
      "Parsed 692 of 170653\n",
      "Parsed 693 of 170653\n",
      "Parsed 694 of 170653\n",
      "Parsed 695 of 170653\n",
      "Parsed 696 of 170653\n",
      "Parsed 697 of 170653\n",
      "Parsed 698 of 170653\n",
      "Parsed 699 of 170653\n",
      "Parsed 700 of 170653\n",
      "Parsed 701 of 170653\n",
      "Parsed 702 of 170653\n",
      "Parsed 703 of 170653\n",
      "Parsed 704 of 170653\n",
      "Parsed 705 of 170653\n",
      "Parsed 706 of 170653\n",
      "Parsed 707 of 170653\n",
      "Parsed 708 of 170653\n",
      "Parsed 709 of 170653\n",
      "Parsed 710 of 170653\n",
      "Parsed 711 of 170653\n",
      "Parsed 712 of 170653\n",
      "Parsed 713 of 170653\n",
      "Parsed 714 of 170653\n",
      "Parsed 715 of 170653\n",
      "Parsed 716 of 170653\n",
      "Parsed 717 of 170653\n",
      "Parsed 718 of 170653\n",
      "Parsed 719 of 170653\n",
      "Parsed 720 of 170653\n",
      "Parsed 721 of 170653\n",
      "Parsed 722 of 170653\n",
      "Parsed 723 of 170653\n",
      "Parsed 724 of 170653\n",
      "Parsed 725 of 170653\n",
      "Parsed 726 of 170653\n",
      "Parsed 727 of 170653\n",
      "Parsed 728 of 170653\n",
      "Parsed 729 of 170653\n",
      "Parsed 730 of 170653\n",
      "Parsed 731 of 170653\n",
      "Parsed 732 of 170653\n",
      "Parsed 733 of 170653\n",
      "Parsed 734 of 170653\n",
      "Parsed 735 of 170653\n",
      "Parsed 736 of 170653\n",
      "Parsed 737 of 170653\n",
      "Parsed 738 of 170653\n",
      "Parsed 739 of 170653\n",
      "Parsed 740 of 170653\n",
      "Parsed 741 of 170653\n",
      "Parsed 742 of 170653\n",
      "Parsed 743 of 170653\n",
      "Parsed 744 of 170653\n",
      "Parsed 745 of 170653\n",
      "Parsed 746 of 170653\n",
      "Parsed 747 of 170653\n",
      "Parsed 748 of 170653\n",
      "Parsed 749 of 170653\n",
      "Parsed 750 of 170653\n",
      "Parsed 751 of 170653\n",
      "Parsed 752 of 170653\n",
      "Parsed 753 of 170653\n",
      "Parsed 754 of 170653\n",
      "Parsed 755 of 170653\n",
      "Parsed 756 of 170653\n",
      "Parsed 757 of 170653\n",
      "Parsed 758 of 170653\n",
      "Parsed 759 of 170653\n",
      "Parsed 760 of 170653\n",
      "Parsed 761 of 170653\n",
      "Parsed 762 of 170653\n",
      "Parsed 763 of 170653\n",
      "Parsed 764 of 170653\n",
      "Parsed 765 of 170653\n",
      "Parsed 766 of 170653\n",
      "Parsed 767 of 170653\n",
      "Parsed 768 of 170653\n",
      "Parsed 769 of 170653\n",
      "Parsed 770 of 170653\n",
      "Parsed 771 of 170653\n",
      "Parsed 772 of 170653\n",
      "Parsed 773 of 170653\n",
      "Parsed 774 of 170653\n",
      "Parsed 775 of 170653\n",
      "Parsed 776 of 170653\n",
      "Parsed 777 of 170653\n",
      "Parsed 778 of 170653\n",
      "Parsed 779 of 170653\n",
      "Parsed 780 of 170653\n",
      "Parsed 781 of 170653\n",
      "Parsed 782 of 170653\n",
      "Parsed 783 of 170653\n",
      "Parsed 784 of 170653\n",
      "Parsed 785 of 170653\n",
      "Parsed 786 of 170653\n",
      "Parsed 787 of 170653\n",
      "Parsed 788 of 170653\n",
      "Parsed 789 of 170653\n",
      "Parsed 790 of 170653\n",
      "Parsed 791 of 170653\n",
      "Parsed 792 of 170653\n",
      "Parsed 793 of 170653\n",
      "Parsed 794 of 170653\n",
      "Parsed 795 of 170653\n",
      "Parsed 796 of 170653\n",
      "Parsed 797 of 170653\n",
      "Parsed 798 of 170653\n",
      "Parsed 799 of 170653\n",
      "Parsed 800 of 170653\n",
      "Parsed 801 of 170653\n",
      "Parsed 802 of 170653\n",
      "Parsed 803 of 170653\n",
      "Parsed 804 of 170653\n",
      "Parsed 805 of 170653\n",
      "Parsed 806 of 170653\n",
      "Parsed 807 of 170653\n",
      "Parsed 808 of 170653\n",
      "Parsed 809 of 170653\n",
      "Parsed 810 of 170653\n",
      "Parsed 811 of 170653\n",
      "Parsed 812 of 170653\n",
      "Parsed 813 of 170653\n",
      "Parsed 814 of 170653\n",
      "Parsed 815 of 170653\n",
      "Parsed 816 of 170653\n",
      "Parsed 817 of 170653\n",
      "Parsed 818 of 170653\n",
      "Parsed 819 of 170653\n",
      "Parsed 820 of 170653\n",
      "Parsed 821 of 170653\n",
      "Parsed 822 of 170653\n",
      "Parsed 823 of 170653\n",
      "Parsed 824 of 170653\n",
      "Parsed 825 of 170653\n",
      "Parsed 826 of 170653\n",
      "Parsed 827 of 170653\n",
      "Parsed 828 of 170653\n",
      "Parsed 829 of 170653\n",
      "Parsed 830 of 170653\n",
      "Parsed 831 of 170653\n",
      "Parsed 832 of 170653\n",
      "Parsed 833 of 170653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 834 of 170653\n",
      "Parsed 835 of 170653\n",
      "Parsed 836 of 170653\n",
      "Parsed 837 of 170653\n",
      "Parsed 838 of 170653\n",
      "Parsed 839 of 170653\n",
      "Parsed 840 of 170653\n",
      "Parsed 841 of 170653\n",
      "Parsed 842 of 170653\n",
      "Parsed 843 of 170653\n",
      "Parsed 844 of 170653\n",
      "Parsed 845 of 170653\n",
      "Parsed 846 of 170653\n",
      "Parsed 847 of 170653\n",
      "Parsed 848 of 170653\n",
      "Parsed 849 of 170653\n",
      "Parsed 850 of 170653\n",
      "Parsed 851 of 170653\n",
      "Parsed 852 of 170653\n",
      "Parsed 853 of 170653\n",
      "Parsed 854 of 170653\n",
      "Parsed 855 of 170653\n",
      "Parsed 856 of 170653\n",
      "Parsed 857 of 170653\n",
      "Parsed 858 of 170653\n",
      "Parsed 859 of 170653\n",
      "Parsed 860 of 170653\n",
      "Parsed 861 of 170653\n",
      "Parsed 862 of 170653\n",
      "Parsed 863 of 170653\n",
      "Parsed 864 of 170653\n",
      "Parsed 865 of 170653\n",
      "Parsed 866 of 170653\n",
      "Parsed 867 of 170653\n",
      "Parsed 868 of 170653\n",
      "Parsed 869 of 170653\n",
      "Parsed 870 of 170653\n",
      "Parsed 871 of 170653\n",
      "Parsed 872 of 170653\n",
      "Parsed 873 of 170653\n",
      "Parsed 874 of 170653\n",
      "Parsed 875 of 170653\n",
      "Parsed 876 of 170653\n",
      "Parsed 877 of 170653\n",
      "Parsed 878 of 170653\n",
      "Parsed 879 of 170653\n",
      "Parsed 880 of 170653\n",
      "Parsed 881 of 170653\n",
      "Parsed 882 of 170653\n",
      "Parsed 883 of 170653\n",
      "Parsed 884 of 170653\n",
      "Parsed 885 of 170653\n",
      "Parsed 886 of 170653\n",
      "Parsed 887 of 170653\n",
      "Parsed 888 of 170653\n",
      "Parsed 889 of 170653\n",
      "Parsed 890 of 170653\n",
      "Parsed 891 of 170653\n",
      "Parsed 892 of 170653\n",
      "Parsed 893 of 170653\n",
      "Parsed 894 of 170653\n",
      "Parsed 895 of 170653\n",
      "Parsed 896 of 170653\n",
      "Parsed 897 of 170653\n",
      "Parsed 898 of 170653\n",
      "Parsed 899 of 170653\n",
      "Parsed 900 of 170653\n",
      "Parsed 901 of 170653\n",
      "Parsed 902 of 170653\n",
      "Parsed 903 of 170653\n",
      "Parsed 904 of 170653\n",
      "Parsed 905 of 170653\n",
      "Parsed 906 of 170653\n",
      "Parsed 907 of 170653\n",
      "Parsed 908 of 170653\n",
      "Parsed 909 of 170653\n",
      "Parsed 910 of 170653\n",
      "Parsed 911 of 170653\n",
      "Parsed 912 of 170653\n",
      "Parsed 913 of 170653\n",
      "Parsed 914 of 170653\n",
      "Parsed 915 of 170653\n",
      "Parsed 916 of 170653\n",
      "Parsed 917 of 170653\n",
      "Parsed 918 of 170653\n",
      "Parsed 919 of 170653\n",
      "Parsed 920 of 170653\n",
      "Parsed 921 of 170653\n",
      "Parsed 922 of 170653\n",
      "Parsed 923 of 170653\n",
      "Parsed 924 of 170653\n",
      "Parsed 925 of 170653\n",
      "Parsed 926 of 170653\n",
      "Parsed 927 of 170653\n",
      "Parsed 928 of 170653\n",
      "Parsed 929 of 170653\n",
      "Parsed 930 of 170653\n",
      "Parsed 931 of 170653\n",
      "Parsed 932 of 170653\n",
      "Parsed 933 of 170653\n",
      "Parsed 934 of 170653\n",
      "Parsed 935 of 170653\n",
      "Parsed 936 of 170653\n",
      "Parsed 937 of 170653\n",
      "Parsed 938 of 170653\n",
      "Parsed 939 of 170653\n",
      "Parsed 940 of 170653\n",
      "Parsed 941 of 170653\n",
      "Parsed 942 of 170653\n",
      "Parsed 943 of 170653\n",
      "Parsed 944 of 170653\n",
      "Parsed 945 of 170653\n",
      "Parsed 946 of 170653\n",
      "Parsed 947 of 170653\n",
      "Parsed 948 of 170653\n",
      "Parsed 949 of 170653\n",
      "Parsed 950 of 170653\n",
      "Parsed 951 of 170653\n",
      "Parsed 952 of 170653\n",
      "Parsed 953 of 170653\n",
      "Parsed 954 of 170653\n",
      "Parsed 955 of 170653\n",
      "Parsed 956 of 170653\n",
      "Parsed 957 of 170653\n",
      "Parsed 958 of 170653\n",
      "Parsed 959 of 170653\n",
      "Parsed 960 of 170653\n",
      "Parsed 961 of 170653\n",
      "Parsed 962 of 170653\n",
      "Parsed 963 of 170653\n",
      "Parsed 964 of 170653\n",
      "Parsed 965 of 170653\n",
      "Parsed 966 of 170653\n",
      "Parsed 967 of 170653\n",
      "Parsed 968 of 170653\n",
      "Parsed 969 of 170653\n",
      "Parsed 970 of 170653\n",
      "Parsed 971 of 170653\n",
      "Parsed 972 of 170653\n",
      "Parsed 973 of 170653\n",
      "Parsed 974 of 170653\n",
      "Parsed 975 of 170653\n",
      "Parsed 976 of 170653\n",
      "Parsed 977 of 170653\n",
      "Parsed 978 of 170653\n",
      "Parsed 979 of 170653\n",
      "Parsed 980 of 170653\n",
      "Parsed 981 of 170653\n",
      "Parsed 982 of 170653\n",
      "Parsed 983 of 170653\n",
      "Parsed 984 of 170653\n",
      "Parsed 985 of 170653\n",
      "Parsed 986 of 170653\n",
      "Parsed 987 of 170653\n",
      "Parsed 988 of 170653\n",
      "Parsed 989 of 170653\n",
      "Parsed 990 of 170653\n",
      "Parsed 991 of 170653\n",
      "Parsed 992 of 170653\n",
      "Parsed 993 of 170653\n",
      "Parsed 994 of 170653\n",
      "Parsed 995 of 170653\n",
      "Parsed 996 of 170653\n",
      "Parsed 997 of 170653\n",
      "Parsed 998 of 170653\n",
      "Parsed 999 of 170653\n",
      "Parsed 1000 of 170653\n",
      "Parsed 1001 of 170653\n",
      "Parsed 1002 of 170653\n",
      "Parsed 1003 of 170653\n",
      "Parsed 1004 of 170653\n",
      "Parsed 1005 of 170653\n",
      "Parsed 1006 of 170653\n",
      "Parsed 1007 of 170653\n",
      "Parsed 1008 of 170653\n",
      "Parsed 1009 of 170653\n",
      "Parsed 1010 of 170653\n",
      "Parsed 1011 of 170653\n",
      "Parsed 1012 of 170653\n",
      "Parsed 1013 of 170653\n",
      "Parsed 1014 of 170653\n",
      "Parsed 1015 of 170653\n",
      "Parsed 1016 of 170653\n",
      "Parsed 1017 of 170653\n",
      "Parsed 1018 of 170653\n",
      "Parsed 1019 of 170653\n",
      "Parsed 1020 of 170653\n",
      "Parsed 1021 of 170653\n",
      "Parsed 1022 of 170653\n",
      "Parsed 1023 of 170653\n",
      "Parsed 1024 of 170653\n",
      "Parsed 1025 of 170653\n",
      "Parsed 1026 of 170653\n",
      "Parsed 1027 of 170653\n",
      "Parsed 1028 of 170653\n",
      "Parsed 1029 of 170653\n",
      "Parsed 1030 of 170653\n",
      "Parsed 1031 of 170653\n",
      "Parsed 1032 of 170653\n",
      "Parsed 1033 of 170653\n",
      "Parsed 1034 of 170653\n",
      "Parsed 1035 of 170653\n",
      "Parsed 1036 of 170653\n",
      "Parsed 1037 of 170653\n",
      "Parsed 1038 of 170653\n",
      "Parsed 1039 of 170653\n",
      "Parsed 1040 of 170653\n",
      "Parsed 1041 of 170653\n",
      "Parsed 1042 of 170653\n",
      "Parsed 1043 of 170653\n",
      "Parsed 1044 of 170653\n",
      "Parsed 1045 of 170653\n",
      "Parsed 1046 of 170653\n",
      "Parsed 1047 of 170653\n",
      "Parsed 1048 of 170653\n",
      "Parsed 1049 of 170653\n",
      "Parsed 1050 of 170653\n",
      "Parsed 1051 of 170653\n",
      "Parsed 1052 of 170653\n",
      "Parsed 1053 of 170653\n",
      "Parsed 1054 of 170653\n",
      "Parsed 1055 of 170653\n",
      "Parsed 1056 of 170653\n",
      "Parsed 1057 of 170653\n",
      "Parsed 1058 of 170653\n",
      "Parsed 1059 of 170653\n",
      "Parsed 1060 of 170653\n",
      "Parsed 1061 of 170653\n",
      "Parsed 1062 of 170653\n",
      "Parsed 1063 of 170653\n",
      "Parsed 1064 of 170653\n",
      "Parsed 1065 of 170653\n",
      "Parsed 1066 of 170653\n",
      "Parsed 1067 of 170653\n",
      "Parsed 1068 of 170653\n",
      "Parsed 1069 of 170653\n",
      "Parsed 1070 of 170653\n",
      "Parsed 1071 of 170653\n",
      "Parsed 1072 of 170653\n",
      "Parsed 1073 of 170653\n",
      "Parsed 1074 of 170653\n",
      "Parsed 1075 of 170653\n",
      "Parsed 1076 of 170653\n",
      "Parsed 1077 of 170653\n",
      "Parsed 1078 of 170653\n",
      "Parsed 1079 of 170653\n",
      "Parsed 1080 of 170653\n",
      "Parsed 1081 of 170653\n",
      "Parsed 1082 of 170653\n",
      "Parsed 1083 of 170653\n",
      "Parsed 1084 of 170653\n",
      "Parsed 1085 of 170653\n",
      "Parsed 1086 of 170653\n",
      "Parsed 1087 of 170653\n",
      "Parsed 1088 of 170653\n",
      "Parsed 1089 of 170653\n",
      "Parsed 1090 of 170653\n",
      "Parsed 1091 of 170653\n",
      "Parsed 1092 of 170653\n",
      "Parsed 1093 of 170653\n",
      "Parsed 1094 of 170653\n",
      "Parsed 1095 of 170653\n",
      "Parsed 1096 of 170653\n",
      "Parsed 1097 of 170653\n",
      "Parsed 1098 of 170653\n",
      "Parsed 1099 of 170653\n",
      "Parsed 1100 of 170653\n",
      "Parsed 1101 of 170653\n",
      "Parsed 1102 of 170653\n",
      "Parsed 1103 of 170653\n",
      "Parsed 1104 of 170653\n",
      "Parsed 1105 of 170653\n",
      "Parsed 1106 of 170653\n",
      "Parsed 1107 of 170653\n",
      "Parsed 1108 of 170653\n",
      "Parsed 1109 of 170653\n",
      "Parsed 1110 of 170653\n",
      "Parsed 1111 of 170653\n",
      "Parsed 1112 of 170653\n",
      "Parsed 1113 of 170653\n",
      "Parsed 1114 of 170653\n",
      "Parsed 1115 of 170653\n",
      "Parsed 1116 of 170653\n",
      "Parsed 1117 of 170653\n",
      "Parsed 1118 of 170653\n",
      "Parsed 1119 of 170653\n",
      "Parsed 1120 of 170653\n",
      "Parsed 1121 of 170653\n",
      "Parsed 1122 of 170653\n",
      "Parsed 1123 of 170653\n",
      "Parsed 1124 of 170653\n",
      "Parsed 1125 of 170653\n",
      "Parsed 1126 of 170653\n",
      "Parsed 1127 of 170653\n",
      "Parsed 1128 of 170653\n",
      "Parsed 1129 of 170653\n",
      "Parsed 1130 of 170653\n",
      "Parsed 1131 of 170653\n",
      "Parsed 1132 of 170653\n",
      "Parsed 1133 of 170653\n",
      "Parsed 1134 of 170653\n",
      "Parsed 1135 of 170653\n",
      "Parsed 1136 of 170653\n",
      "Parsed 1137 of 170653\n",
      "Parsed 1138 of 170653\n",
      "Parsed 1139 of 170653\n",
      "Parsed 1140 of 170653\n",
      "Parsed 1141 of 170653\n",
      "Parsed 1142 of 170653\n",
      "Parsed 1143 of 170653\n",
      "Parsed 1144 of 170653\n",
      "Parsed 1145 of 170653\n",
      "Parsed 1146 of 170653\n",
      "Parsed 1147 of 170653\n",
      "Parsed 1148 of 170653\n",
      "Parsed 1149 of 170653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8853bacba0ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Removes any duplicate genres in the list and appends it as a string to the new genres column for the given song.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mgenreAdjustmentDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genres'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenresList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parsed '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of 170653'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                 \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                     \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36msetter\u001b[0;34m(item, v)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0;31m# reset the sliced object if unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;31m# we need an iterable, with a ndim of at least 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3625\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, locs, values)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creates a new DataFrame based on the existing data.csv.\n",
    "\n",
    "genreAdjustmentDf = df.copy()\n",
    "\n",
    "# Adds a 'genres' column to the new DataFrame.\n",
    "\n",
    "genreAdjustmentDf['genres'] = ''\n",
    "\n",
    "# Iterates over every row in the new DataFrame.\n",
    "\n",
    "for index, row in genreAdjustmentDf.iterrows():\n",
    "    \n",
    "    # Parses the string data in the 'artists' column into a list of individual artists that are acredited to the given song. \n",
    "    \n",
    "    artists = row.get('artists').replace('[', '').replace(']', '').replace(\"'\", '').split(', ')\n",
    "    \n",
    "    genresList = []\n",
    "    \n",
    "    # Iterates over each artist in the accredited list.\n",
    "    \n",
    "    for artist in artists:\n",
    "        \n",
    "        # Searches the artists with genres DataFrame for a match with the given artist. Returns the row as a Series.\n",
    "        \n",
    "        target = genresDf.loc[genresDf['artists'] == artist].squeeze()\n",
    "        \n",
    "        # Parses the string data in the 'genres' column into a list of individual genres that are assosiated with the given artist. Appends this list to an existing list if there are multiple given artists.\n",
    "        \n",
    "        genresList = genresList + str(target.get('genres')).replace('[', '').replace(']', '').replace(\"'\", '').split(', ')\n",
    "        \n",
    "    # Removes any duplicate genres in the list and appends it as a string to the new genres column for the given song.\n",
    "\n",
    "    genreAdjustmentDf.loc[index, 'genres'] = str(list(set(genresList)))\n",
    "    \n",
    "    print('Parsed ' + str(index + 1) + ' of 170653')\n",
    "    \n",
    "# Exports the new DataFrame as a new csv file called songs_w_genres.csv so it can be used without needing to parse again.\n",
    "                         \n",
    "genreAdjustmentDf.to_csv(r'songs_w_genres.csv', index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now look up a songs by the previously given artists we can see that on the end there is now a 'genres' column at the end of the DataFrame which features the genres of the accredited artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18137</th>\n",
       "      <td>0.235</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>['Lana Del Rey']</td>\n",
       "      <td>0.565</td>\n",
       "      <td>265427</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0</td>\n",
       "      <td>2dBwB667LHQkLhdYlwLUZK</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-6.826</td>\n",
       "      <td>0</td>\n",
       "      <td>Summertime Sadness</td>\n",
       "      <td>63</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>111.968</td>\n",
       "      <td>['art pop', 'pop']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       valence  year  acousticness           artists  danceability  \\\n",
       "18137    0.235  2012        0.0542  ['Lana Del Rey']         0.565   \n",
       "\n",
       "       duration_ms  energy  explicit                      id  \\\n",
       "18137       265427   0.654         0  2dBwB667LHQkLhdYlwLUZK   \n",
       "\n",
       "       instrumentalness  key  liveness  loudness  mode                name  \\\n",
       "18137          0.000002    1     0.122    -6.826     0  Summertime Sadness   \n",
       "\n",
       "       popularity release_date  speechiness    tempo              genres  \n",
       "18137          63   2012-11-12       0.0335  111.968  ['art pop', 'pop']  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songsGenresDf = pd.read_csv('songs_w_genres.csv')\n",
    "\n",
    "songsGenresDf.loc[songsGenresDf['name'] == 'Summertime Sadness'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74002</th>\n",
       "      <td>0.633</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>['Royal Blood']</td>\n",
       "      <td>0.52</td>\n",
       "      <td>240572</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1</td>\n",
       "      <td>2nIulsLMiP2SMTDrtxfQXX</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>2</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>1</td>\n",
       "      <td>Out of the Black</td>\n",
       "      <td>53</td>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>158.937</td>\n",
       "      <td>['modern blues rock', 'garage rock', 'modern a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       valence  year  acousticness          artists  danceability  \\\n",
       "74002    0.633  2014      0.000867  ['Royal Blood']          0.52   \n",
       "\n",
       "       duration_ms  energy  explicit                      id  \\\n",
       "74002       240572   0.981         1  2nIulsLMiP2SMTDrtxfQXX   \n",
       "\n",
       "       instrumentalness  key  liveness  loudness  mode              name  \\\n",
       "74002           0.00177    2     0.197     -2.75     1  Out of the Black   \n",
       "\n",
       "       popularity release_date  speechiness    tempo  \\\n",
       "74002          53   2014-08-25       0.0906  158.937   \n",
       "\n",
       "                                                  genres  \n",
       "74002  ['modern blues rock', 'garage rock', 'modern a...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songsGenresDf.loc[songsGenresDf['name'] == 'Out of the Black'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11013</th>\n",
       "      <td>0.706</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.292</td>\n",
       "      <td>['Bill Withers']</td>\n",
       "      <td>0.69</td>\n",
       "      <td>254560</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0</td>\n",
       "      <td>0bRXwKfigvpKZUurwqAlEh</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>9</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-8.267</td>\n",
       "      <td>1</td>\n",
       "      <td>Lovely Day</td>\n",
       "      <td>76</td>\n",
       "      <td>1977-10-29</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>97.918</td>\n",
       "      <td>['motown', 'funk', 'quiet storm', 'soul']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       valence  year  acousticness           artists  danceability  \\\n",
       "11013    0.706  1977         0.292  ['Bill Withers']          0.69   \n",
       "\n",
       "       duration_ms  energy  explicit                      id  \\\n",
       "11013       254560   0.651         0  0bRXwKfigvpKZUurwqAlEh   \n",
       "\n",
       "       instrumentalness  key  liveness  loudness  mode        name  \\\n",
       "11013           0.00241    9     0.105    -8.267     1  Lovely Day   \n",
       "\n",
       "       popularity release_date  speechiness   tempo  \\\n",
       "11013          76   1977-10-29       0.0324  97.918   \n",
       "\n",
       "                                          genres  \n",
       "11013  ['motown', 'funk', 'quiet storm', 'soul']  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songsGenresDf.loc[songsGenresDf['name'] == 'Lovely Day'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also if we take a look at a song that features multiple accredited artists we can see that the genres of both artists have been combined, without duplicating genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artists: ['Lionel Richie', 'Diana Ross']\n",
      "Lionel Richie - Genres: ['adult standards', 'disco', 'mellow gold', 'motown', 'quiet storm', 'soft rock']\n",
      "Diana Ross - Genres: ['adult standards', 'disco', 'funk', 'mellow gold', 'motown', 'quiet storm', 'soft rock', 'soul']\n",
      "Combined Genres for Endless Love: ['soft rock', 'funk', 'quiet storm', 'motown', 'mellow gold', 'disco', 'adult standards', 'soul']\n"
     ]
    }
   ],
   "source": [
    "target = songsGenresDf.loc[songsGenresDf['name'] == 'Endless Love'].head(1).squeeze()\n",
    "\n",
    "print('Artists: ' + str(target.get('artists')))\n",
    "\n",
    "print('Lionel Richie - Genres: ' + str(genresDf.loc[genresDf['artists'] == 'Lionel Richie'].squeeze().get('genres'))) \n",
    "print('Diana Ross - Genres: ' + str(genresDf.loc[genresDf['artists'] == 'Diana Ross'].squeeze().get('genres')))\n",
    "\n",
    "print('Combined Genres for Endless Love: ' + str(target.get('genres')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have the genres featured for each song, let's see if this will improve the accuracy of the Linear Regression model.\n",
    "\n",
    "Firstly we need to drop the irrelevant columns from the new data frame. Then we need to encode the genres into unique integer values the same way we did with the artists earlier. So we can use the same function: 'encodeStrings()'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 113.38291980221359\n",
      "R^2: 0.7618839225034588\n",
      "Accuracy: 76.18839%\n",
      "\n",
      "=== Genre Addition Accuracy: 76.18839% ===\n"
     ]
    }
   ],
   "source": [
    "songsGenresDf = pd.read_csv('songs_w_genres.csv')\n",
    "\n",
    "songsGenresDf = songsGenresDf.drop(columns=['id', 'release_date', 'name', 'mode'])\n",
    "\n",
    "songsGenresDf['artists'] = encodeStrings(songsGenresDf, 'artists')\n",
    "songsGenresDf['genres'] = encodeStrings(songsGenresDf, 'genres')\n",
    "\n",
    "print(\"=== Genre Addition Accuracy: {:.5f}% ===\".format((train(songsGenresDf)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has added 0.06223% to the accuracy a massive improvement.\n",
    "\n",
    "To check if Linear Regression is the best Regressor for this task I will try RidgeCV regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 117.94334271441588\n",
      "R^2: 0.7523065539062024\n",
      "Accuracy: 75.23066%\n",
      "\n",
      "=== Baseline Accuracy: 75.23066% ===\n"
     ]
    }
   ],
   "source": [
    "def ridgeTrain(data):\n",
    "    \n",
    "    # Sets the subject and target DataFrames. \n",
    "    \n",
    "    dataIn = data.drop(columns=['popularity'])\n",
    "    dataOut = data['popularity']\n",
    "\n",
    "    dataInTrain, dataInTest, dataOutTrain, dataOutTest = train_test_split(dataIn, dataOut, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = linear_model.OrthogonalMatchingPursuit()\n",
    "    model.fit(dataInTrain, dataOutTrain)\n",
    "\n",
    "    predictions = model.predict(dataInTest)\n",
    "    \n",
    "    print(\"MSE: \" + str(mean_squared_error(dataOutTest, predictions)))\n",
    "\n",
    "    print(\"R^2: \" + str(r2_score(dataOutTest, predictions)))\n",
    "\n",
    "    accuracy = model.score(dataInTest, dataOutTest)\n",
    "    \n",
    "    print(\"Accuracy: {:.5f}%\\n\".format(accuracy * 100))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "print(\"=== Baseline Accuracy: {:.5f}% ===\".format((ridgeTrain(songsGenresDf)) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Filtering\n",
    "\n",
    "Starting work on content based filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 154165 is out of bounds for axis 0 with size 38000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-40fa5c5b81e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreccomendationDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lovely Day\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_sim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-40fa5c5b81e0>\u001b[0m in \u001b[0;36mget_recommendations\u001b[0;34m(name, cosine_sim)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0msim_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 154165 is out of bounds for axis 0 with size 38000"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "reccomendationDF = pd.read_csv('songs_w_genres.csv')\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(reccomendationDF['genres'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
